{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "5gSr4bKn_NPo"
      },
      "source": [
        "# Import libraries\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from skimage import data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz3yaPOyyOYp"
      },
      "source": [
        "## Pooling\n",
        "\n",
        "Documentation: https://pytorch.org/docs/stable/nn.html#torch.nn.MaxPool2d\n",
        "\n",
        "```python\n",
        "torch.nn.MaxPool2d(kernel_size, stride=None, padding=0)\n",
        "```\n",
        "\n",
        "**```kernel_size```** <br>\n",
        "*Field of View* size. It can be a tuple or a single number. Ex: ```kernel_size = 3``` will set FoV of $3 \\times 3$\n",
        "\n",
        "**```stride```** <br>\n",
        "Controls sliding window jumping.\n",
        "\n",
        "**```padding```** <br>\n",
        "Filling with zeros on the edges of the image.\n",
        "\n",
        "The pooling layer expects input of **at least** 3 dimensions ($C \\times H \\times W$), but in general the network will also provide the batch dimension ($B \\times C \\times H \\ teams W$)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_6nSeAGyuSR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be53de3f-29b6-4788-9b39-17303da1aa80"
      },
      "source": [
        "# Create a tensor with the following values\n",
        "\n",
        "tns = torch.FloatTensor([ [ [ 1, 2,3 ],\n",
        "                            [4,5,6],\n",
        "                            [7,8,9]  ] ] )\n",
        "\n",
        "# Create a 2D max pooling layer with a kernel size of 2 and a stride of 1\n",
        "\n",
        "pool = nn.MaxPool2d(2, stride=1)\n",
        "saida = pool(tns)\n",
        "\n",
        "print(tns.size())\n",
        "print(tns)\n",
        "print(saida.size())\n",
        "print(saida)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 3, 3])\n",
            "tensor([[[1., 2., 3.],\n",
            "         [4., 5., 6.],\n",
            "         [7., 8., 9.]]])\n",
            "torch.Size([1, 2, 2])\n",
            "tensor([[[5., 6.],\n",
            "         [8., 9.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_xGNalT1e2k"
      },
      "source": [
        "When processing data with multiple channels, the pooling layer processes each input channel separately instead of processing all channels as in a convolutional layer. This means that **the number of output channels for the pooling layer is the same as the number of input channels**.\n",
        "\n",
        "Let's process the image of the astronaut below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfXYSTkH0gmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ee13e69-12bd-405d-efd8-3b014bc9cd4f"
      },
      "source": [
        "# Create a convolutional layer with 3 input channels, 16 output channels, a kernel size of 3, and padding of 1\n",
        "\n",
        "conv = nn.Conv2d(in_channels=3, out_channels=16,\n",
        "                 kernel_size=3, padding=1)\n",
        "\n",
        "rgb = data.astronaut()\n",
        "\n",
        "# Convert the image to a tensor\n",
        "\n",
        "rgb_tns = torch.Tensor(rgb)\n",
        "\n",
        "# Permute the dimensions of the tensor so that the channels are first\n",
        "\n",
        "rgb_tns = rgb_tns.permute(2, 0, 1).unsqueeze(0)\n",
        "\n",
        "# Apply the convolutional layer to the tensor\n",
        "\n",
        "mapa_de_ativacao = conv(rgb_tns)\n",
        "print('Feature Map:', mapa_de_ativacao.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Map: torch.Size([1, 16, 512, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfyfZmZd1iH8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b1da5d-661c-4b2b-d137-6e9b81eb7d5a"
      },
      "source": [
        "# Create a 2D max pooling layer with a kernel size of 2\n",
        "\n",
        "pool = nn.MaxPool2d(kernel_size=2)\n",
        "saida = pool(mapa_de_ativacao)\n",
        "print(saida.size())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 256, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M62eNRKDpS1g"
      },
      "source": [
        "## Batch Normalization\n",
        "\n",
        "Documentation: https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm2d\n",
        "\n",
        "```python\n",
        "torch.nn.BatchNorm2d(num_features)\n",
        "```\n",
        "\n",
        "**```num_features```**<br>\n",
        "$\\mathbf{\\gamma}$ and $\\mathbf{\\beta}$ are learned individually for each input channel. In intermediate layer activations, this value corresponds to the **number of feature maps**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7rkKA62pUV6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5910ddc-9630-42ab-fea6-af347a8adb43"
      },
      "source": [
        "# Create a convolutional block with the following layers:\n",
        "#   - Convolutional layer with 3 input channels, 32 output channels, a kernel size of 3, and padding of 1\n",
        "#   - Batch normalization layer with 32 channels\n",
        "#   - ReLU activation layer\n",
        "#   - Max pooling layer with a kernel size of 10\n",
        "\n",
        "blococonv = nn.Sequential(\n",
        "            nn.Conv2d(3,32,kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=10)\n",
        ")\n",
        "print(blococonv)\n",
        "\n",
        "# Create a minibatch of 12 copies of the astronaut image\n",
        "\n",
        "minibatch = torch.cat(12*[rgb_tns])\n",
        "\n",
        "# Print the size of the output tensor\n",
        "print(minibatch.size())\n",
        "saida = blococonv(minibatch)\n",
        "print(saida.size())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sequential(\n",
            "  (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (2): ReLU()\n",
            "  (3): MaxPool2d(kernel_size=10, stride=10, padding=0, dilation=1, ceil_mode=False)\n",
            ")\n",
            "torch.Size([12, 3, 512, 512])\n",
            "torch.Size([12, 32, 51, 51])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HZrp-p0T06iI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}